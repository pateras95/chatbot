{"ast":null,"code":"import { GoogleGenerativeAI } from '@google/generative-ai';\nexport default {\n  data() {\n    return {\n      prompt: '',\n      text: 'Hello, i am the museum bot\\n,' + ' how can i help you?',\n      recognition: null,\n      transcript: '',\n      isListening: false\n    };\n  },\n  mounted() {\n    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!SpeechRecognition) {\n      console.log('Speech Recognition API not supported in this browser.');\n    }\n    this.recognition = new SpeechRecognition();\n    this.recognition.lang = 'en-US';\n    this.recognition.continuous = true;\n    this.recognition.interimResults = true;\n\n    // Bind event handlers\n    this.recognition.onresult = this.onSpeechResult;\n    this.recognition.onerror = this.onSpeechError;\n    this.recognition.onend = this.onSpeechEnd;\n    const utterance = new SpeechSynthesisUtterance(this.text);\n    speechSynthesis.speak(utterance);\n    utterance.onend = event => {\n      this.text = ''; // end animation\n      this.startListening();\n    };\n  },\n  methods: {\n    async generateText() {\n      const genAI = new GoogleGenerativeAI(process.env.VUE_APP_GOOGLE_GENAI_API_KEY);\n      const model = genAI.getGenerativeModel({\n        model: 'gemini-1.5-flash'\n      });\n      const result = await model.generateContent(this.prompt);\n      const response = await result.response;\n      this.text = response.text();\n      if (this.text !== '') {\n        this.speak();\n      }\n    },\n    speak() {\n      const utterance = new SpeechSynthesisUtterance(this.text);\n      speechSynthesis.speak(utterance);\n      utterance.onend = event => {\n        this.text = ''; // end animation\n      };\n    },\n    startListening() {\n      if (this.recognition) {\n        this.recognition.start();\n        this.isListening = true;\n        this.error = '';\n      }\n    },\n    stopListening() {\n      if (this.recognition) {\n        this.recognition.stop();\n        this.isListening = false;\n      }\n    },\n    onSpeechResult(event) {\n      const transcript = Array.from(event.results).map(result => result[0].transcript).join('');\n      this.transcript = transcript;\n    },\n    onSpeechError(event) {\n      this.error = `Error occurred in recognition: ${event.error}`;\n      this.isListening = false;\n    },\n    onSpeechEnd() {\n      this.isListening = false;\n      console.log(this.transcript);\n      // this.generateText()\n    }\n  }\n};","map":{"version":3,"names":["GoogleGenerativeAI","data","prompt","text","recognition","transcript","isListening","mounted","SpeechRecognition","window","webkitSpeechRecognition","console","log","lang","continuous","interimResults","onresult","onSpeechResult","onerror","onSpeechError","onend","onSpeechEnd","utterance","SpeechSynthesisUtterance","speechSynthesis","speak","event","startListening","methods","generateText","genAI","process","env","VUE_APP_GOOGLE_GENAI_API_KEY","model","getGenerativeModel","result","generateContent","response","start","error","stopListening","stop","Array","from","results","map","join"],"sources":["src/App.vue"],"sourcesContent":["<template>\n    <div id=\"app\">\n        <div id=\"container\">\n            <div id=\"bot\" :class=\"{'speaking': text}\">\n                <div id=\"head\">\n                    <div id=\"left-ear\">\n                        <div id=\"left-ear-inner\"></div>\n                    </div>\n                    <div id=\"face\">\n                        <div id=\"eyes\">\n                            <div id=\"left-eye\"></div>\n                            <div id=\"right-eye\"></div>\n                        </div>\n                        <div id=\"mouth\"></div>\n                    </div>\n                    <div id=\"right-ear\">\n                        <div id=\"right-ear-inner\"></div>\n                    </div>\n                </div>\n            </div>\n        </div>\n        <p class=\"spoken-text\"  v-if=\"text\">{{ text }}</p>\n        <input type=\"text\" v-model=\"transcript\" placeholder=\"Enter your prompt...\" />\n        <button @click=\"generateText\">Generate Text</button>\n\n        <button @click=\"startListening\">Start Listening</button>\n        <button @click=\"stopListening\" :disabled=\"!isListening\">Stop Listening</button>\n        <p v-if=\"transcript\">Transcript: {{ transcript }}</p>\n    </div>\n</template>\n\n<script>\n    import { GoogleGenerativeAI } from '@google/generative-ai'\n\n    export default {\n        data() {\n            return {\n                prompt: '',\n                text: 'Hello, i am the museum bot\\n,' +\n                    ' how can i help you?',\n                recognition: null,\n                transcript: '',\n                isListening: false\n            }\n        },\n        mounted() {\n            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition\n            if (!SpeechRecognition) {\n                console.log('Speech Recognition API not supported in this browser.')\n            }\n            this.recognition = new SpeechRecognition()\n            this.recognition.lang = 'en-US'\n            this.recognition.continuous = true\n            this.recognition.interimResults = true\n\n            // Bind event handlers\n            this.recognition.onresult = this.onSpeechResult\n            this.recognition.onerror = this.onSpeechError\n            this.recognition.onend = this.onSpeechEnd\n\n            const utterance = new SpeechSynthesisUtterance(this.text)\n            speechSynthesis.speak(utterance)\n            utterance.onend = (event) => {\n                this.text = '' // end animation\n                this.startListening()\n            }\n        },\n        methods: {\n            async generateText() {\n                const genAI = new GoogleGenerativeAI(process.env.VUE_APP_GOOGLE_GENAI_API_KEY)\n                const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' })\n\n                const result = await model.generateContent(this.prompt)\n                const response = await result.response\n                this.text = response.text()\n                if (this.text !== '') {\n                    this.speak()\n                }\n            },\n            speak() {\n                const utterance = new SpeechSynthesisUtterance(this.text)\n                speechSynthesis.speak(utterance)\n                utterance.onend = (event) => {\n                    this.text = '' // end animation\n                }\n            },\n            startListening() {\n                if (this.recognition) {\n                    this.recognition.start()\n                    this.isListening = true\n                    this.error = ''\n                }\n            },\n            stopListening() {\n                if (this.recognition) {\n                    this.recognition.stop()\n                    this.isListening = false\n                }\n            },\n            onSpeechResult(event) {\n                const transcript = Array.from(event.results)\n                    .map(result => result[0].transcript)\n                    .join('')\n                this.transcript = transcript\n            },\n            onSpeechError(event) {\n                this.error = `Error occurred in recognition: ${event.error}`\n                this.isListening = false\n            },\n            onSpeechEnd() {\n                this.isListening = false\n                console.log(this.transcript)\n                // this.generateText()\n            }\n        }\n    }\n</script>\n\n<style>\n/* Add some basic styling */\n#app {\n  font-family: Avenir, Helvetica, Arial, sans-serif;\n  background-color: #000;\n  color: #FFF;\n  margin-top: 60px;\n}\n\n.spoken-text{\n  text-align: center;\n}\n\ninput {\n  padding: 10px;\n  font-size: 16px;\n  margin-right: 10px;\n}\n\nbutton {\n  padding: 10px;\n  font-size: 16px;\n}\n\np {\n  margin-top: 20px;\n  font-size: 18px;\n}\n\n#bot\n{\n  position: relative;\n  text-align: left;\n  width: 24em;\n  height: 24em;\n  min-width: 10em;\n  min-height: 10em;\n  /*border: 1px solid lightblue;*/\n  margin: 0 auto;\n}\n\n#head\n{\n  position: relative;\n  display: inline-block;\n  margin-top: 15%;\n  margin-left: 10%;\n  width: 80%;\n  height: 70%;\n  /*border : 1px solid yellow;*/\n}\n\n#face\n{\n  position: absolute;\n  margin-left: 0%;\n  margin-right: 0%;\n  width: 100%;\n  height: 100%;\n  border: 0.4em solid #FFF;\n  border-radius: 1.5em;\n  /*border : 1px solid red;*/\n}\n\n#left-ear, #right-ear\n{\n  position: absolute;\n  top: 30%;\n  width: 6%;\n  height: 25%;\n  border: 0.15em solid #FFF;\n  background-color: lightgray;\n  border-radius: 0.1em;\n}\n\n#left-ear\n{\n  left: -6%;\n}\n\n#right-ear\n{\n  right: -10%;\n}\n\n#left-ear-inner, #right-ear-inner\n{\n  position: absolute;\n  top: 20%;\n  width: 100%;\n  height: 60%;\n  background-color: lightgray;\n  border-radius: 0.1em;\n}\n\n#left-ear-inner\n{\n  left: -150%;\n}\n\n#right-ear-inner\n{\n  right: -150%;\n}\n\n#eyes\n{\n  position: absolute;\n  width: 70%;\n  height: 20%;\n  margin-left: 16%; /* 16 */\n  margin-top: 20%; /* 20 */\n  /*border : 1px solid lightseagreen;*/\n}\n\n#left-eye, #right-eye\n{\n  position: absolute;\n  width: 35%;\n  height: 100%;\n  background-color: lightseagreen;\n  border-radius: 0.5em;\n  /*border: 0.15em solid #FFF;*/\n}\n\n#right-eye\n{\n  right: 0%;\n}\n\n#mouth\n{\n  position: absolute;\n  width: 30%;\n  height: 4%;\n  border-left: 0.2em solid #FFF;\n  border-right: 0.2em solid #FFF;\n  border-bottom: 0.2em solid #FFF;\n  border-top: 0.0em solid #FFF;\n  border-radius: 0.5em;\n  left: 35%;\n  bottom: 20%;\n}\n\n/* Animations */\n#bot.neutral #left-eye, #bot.neutral #right-eye\n{\n  animation: blink-eyes 3s infinite ease-in alternate;\n  animation-delay: 2s;\n}\n\n#bot.neutral #left-ear-inner\n{\n  animation: move-left-ear-inner 5.0s infinite ease alternate;\n}\n\n#bot.neutral #right-ear-inner\n{\n  animation: move-right-ear-inner 5.0s infinite ease alternate;\n}\n\n@keyframes blink-eyes {\n  0%   { height: 10%; margin-top: 10%}\n  10% { height: 100%; margin-top: 0%}\n  100% { height: 100%; margin-top: 0%}\n}\n\n/* Speaking */\n#bot.speaking #mouth\n{\n  border-top: 0.2em solid #FFF;\n  background-color: #FFF;\n  animation: speak-mouth 1.0s infinite ease alternate;\n}\n\n@keyframes speak-mouth {\n  0%   { width: 10%; height: 4%; left: 45%;}\n  25% { width: 30%; height: 10%; left: 35%;}\n  50% { width: 6%; height: 4%; left: 47%;}\n  75% { width: 40%; height: 8%; left: 30%;}\n  100% { width: 30%; height: 4%; left: 35%;}\n}\n\n/* Waiting (Thinking) */\n#bot.thinking #eyes\n{\n  animation: glance-eyes 8s infinite ease-in-out;\n  animation-delay: 2s;\n}\n\n#bot.thinking #mouth\n{\n  animation: pinch-mouth 6.0s infinite ease alternate;\n  animation-delay: 4s;\n}\n\n#bot.thinking #left-ear-inner\n{\n  animation: move-left-ear-inner 6.0s infinite ease alternate;\n  animation-delay: 4s;\n}\n\n#bot.thinking #right-ear-inner\n{\n  animation: move-right-ear-inner 6.0s infinite ease alternate;\n  animation-delay: 4s;\n}\n\n@keyframes glance-eyes {\n  0%  { margin-left: 16%; }\n  10% { margin-left: 6%; }\n  40% { margin-left: 6%; }\n  60% { margin-left: 24%; }\n  70% { margin-left: 24%; }\n  80% { margin-left: 16%; }\n  100% { margin-left: 16%; }\n}\n\n@keyframes pinch-mouth {\n  0%   { width: 30%; left: 35%; }\n  48%  { width: 30%; left: 35%; }\n  50%  { width: 10%; left: 45%; }\n  52%  { width: 30%; left: 35%; }\n  100% { width: 30%; left: 35%;}\n}\n\n@keyframes move-left-ear-inner {\n  0%   { left: -150%; }\n  48%  { left: -150%; }\n  50%  { left: -100%; }\n  52%  { left: -150%; }\n  100% { left: -150%; }\n}\n\n@keyframes move-right-ear-inner {\n  0%   { right: -150%; }\n  48%  { right: -150%; }\n  50%  { right: -100%; }\n  52%  { right: -150%; }\n  100% { right: -150%; }\n}\n\n/* Listening */\n#bot.listening #left-eye, #bot.listening #right-eye\n{\n  background-color: lightgreen;\n  border-radius: 1em;\n  transition : border-radius 0.25s linear;\n  animation: none;\n}\n\n#bot.listening #left-ear, #bot.listening #right-ear,\n#bot.listening #left-ear-inner, #bot.listening #right-ear-inner\n{\n  background-color: lightgreen;\n}\n\n#bot.listening #face,\n#bot.listening #left-ear, #bot.listening #right-ear\n{\n  border-color: lightgreen;\n  transition : border-color 0.25s linear;\n}\n\n#bot.listening #left-ear-inner,\n#bot.listening #right-ear-inner\n{\n  /*outline: 0.4em dotted lightgreen;*/\n  animation: border-bump 0.4s infinite ease alternate;\n  animation-delay: 0.5s;\n}\n\n@keyframes border-bump {\n  0% {\n    outline: 0.4em dotted lightgreen;\n  }\n\n  100% {\n    outline: 0.2em dotted black;\n  }\n}\n\n/* Computing */\n#bot.computing #left-eye, #bot.computing #right-eye\n{\n  height: 100%;\n  width: 25%;\n  border-radius: 100%;\n  transition : all 0.25s linear;\n  border: 0.3em dashed black;\n  animation-delay: 0.5s;\n  background-color: #99FFFF;\n}\n\n#bot.computing #left-eye\n{\n  animation: border-dance 1s infinite linear reverse;\n}\n\n#bot.computing #right-eye\n{\n  animation: border-dance 1s infinite linear;\n}\n\n#bot.computing #face,\n#bot.computing #left-ear, #bot.computing #right-ear,\n#bot.computing #left-ear-inner, #bot.computing #right-ear-inner\n{\n  border-color: #99FFFF;\n  transition : border-color 0.25s linear;\n}\n\n#bot.computing #left-ear, #bot.computing #right-ear,\n#bot.computing #left-ear-inner, #bot.computing #right-ear-inner\n{\n  background-color: #99FFFF;\n  transition : background-color 0.25s linear;\n  animation: none;\n}\n\n#bot.computing #mouth\n{\n  border: 0.5em solid #FFF;\n  width: 10%;\n  left: 45%;\n}\n\n@keyframes border-dance {\n  100% {\n    transform: rotateZ(360deg);\n  }\n}\n</style>\n"],"mappings":"AAgCA,SAAAA,kBAAA;AAEA;EACAC,KAAA;IACA;MACAC,MAAA;MACAC,IAAA,oCACA;MACAC,WAAA;MACAC,UAAA;MACAC,WAAA;IACA;EACA;EACAC,QAAA;IACA,MAAAC,iBAAA,GAAAC,MAAA,CAAAD,iBAAA,IAAAC,MAAA,CAAAC,uBAAA;IACA,KAAAF,iBAAA;MACAG,OAAA,CAAAC,GAAA;IACA;IACA,KAAAR,WAAA,OAAAI,iBAAA;IACA,KAAAJ,WAAA,CAAAS,IAAA;IACA,KAAAT,WAAA,CAAAU,UAAA;IACA,KAAAV,WAAA,CAAAW,cAAA;;IAEA;IACA,KAAAX,WAAA,CAAAY,QAAA,QAAAC,cAAA;IACA,KAAAb,WAAA,CAAAc,OAAA,QAAAC,aAAA;IACA,KAAAf,WAAA,CAAAgB,KAAA,QAAAC,WAAA;IAEA,MAAAC,SAAA,OAAAC,wBAAA,MAAApB,IAAA;IACAqB,eAAA,CAAAC,KAAA,CAAAH,SAAA;IACAA,SAAA,CAAAF,KAAA,GAAAM,KAAA;MACA,KAAAvB,IAAA;MACA,KAAAwB,cAAA;IACA;EACA;EACAC,OAAA;IACA,MAAAC,aAAA;MACA,MAAAC,KAAA,OAAA9B,kBAAA,CAAA+B,OAAA,CAAAC,GAAA,CAAAC,4BAAA;MACA,MAAAC,KAAA,GAAAJ,KAAA,CAAAK,kBAAA;QAAAD,KAAA;MAAA;MAEA,MAAAE,MAAA,SAAAF,KAAA,CAAAG,eAAA,MAAAnC,MAAA;MACA,MAAAoC,QAAA,SAAAF,MAAA,CAAAE,QAAA;MACA,KAAAnC,IAAA,GAAAmC,QAAA,CAAAnC,IAAA;MACA,SAAAA,IAAA;QACA,KAAAsB,KAAA;MACA;IACA;IACAA,MAAA;MACA,MAAAH,SAAA,OAAAC,wBAAA,MAAApB,IAAA;MACAqB,eAAA,CAAAC,KAAA,CAAAH,SAAA;MACAA,SAAA,CAAAF,KAAA,GAAAM,KAAA;QACA,KAAAvB,IAAA;MACA;IACA;IACAwB,eAAA;MACA,SAAAvB,WAAA;QACA,KAAAA,WAAA,CAAAmC,KAAA;QACA,KAAAjC,WAAA;QACA,KAAAkC,KAAA;MACA;IACA;IACAC,cAAA;MACA,SAAArC,WAAA;QACA,KAAAA,WAAA,CAAAsC,IAAA;QACA,KAAApC,WAAA;MACA;IACA;IACAW,eAAAS,KAAA;MACA,MAAArB,UAAA,GAAAsC,KAAA,CAAAC,IAAA,CAAAlB,KAAA,CAAAmB,OAAA,EACAC,GAAA,CAAAV,MAAA,IAAAA,MAAA,IAAA/B,UAAA,EACA0C,IAAA;MACA,KAAA1C,UAAA,GAAAA,UAAA;IACA;IACAc,cAAAO,KAAA;MACA,KAAAc,KAAA,qCAAAd,KAAA,CAAAc,KAAA;MACA,KAAAlC,WAAA;IACA;IACAe,YAAA;MACA,KAAAf,WAAA;MACAK,OAAA,CAAAC,GAAA,MAAAP,UAAA;MACA;IACA;EACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}